{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b97505-bcb9-47db-a192-2a2c867b476e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://www.unir.net/wp-content/uploads/2019/11/Unir_2021_logo.svg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc899f-a395-48d0-b158-5275366be1ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><h1>Sistema inteligente para ayudar a detectar posibles reclamos (glosas) en las cuentas médicas previo al cobro, de una clínica en Colombia - Audimed</h1></center>\n",
    "<center><h2>Trabajo Fin de Master<br>Máster Universitario en Análisis y Visualización de Datos Masivos / Visual Analytics and Big Data</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e947a3d-559e-412a-97ea-b4f6e4dfe42d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Presentado por: Jacqueline Guzmán Rodriguez</h3>\n",
    "<h4>Tipo de trabajo: Desarrollo Software <br>\n",
    "Director: Juan Carlos Rincon Acuña <br>\n",
    "Fecha: Junio/2024</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb07b1b-a9bb-46af-a76b-86d512fea6ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3> <font color=\"#040078\">Notebook de modelado de los datos</font></h3>\n",
    "<h4></h4>\n",
    "<h5><font color=\"#C62400\">Licencia del Notebook CC BY-NC-SA 4.0 DEED <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" target=\"_blank]\">https://creativecommons.org/licenses/by-nc-sa/4.0/</a></font></h5/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2133c-d263-407d-87f9-b785901d98f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importación de librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543eb993-7fe7-4881-8db1-d7ed0f91f340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn_evaluation import plot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445da700-831e-4a03-8da9-713acf28b7e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Carga de archivo con datos transformados claims.cvs\n",
    "#### Se pueden descargar los datos de la plataforma kaggle en el siguiente link: \n",
    "##### https://www.kaggle.com/datasets/jacquelineguzman/claims-of-medical-billing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "728b0476-bdad-446f-a1ff-e0f29808957e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read file CSV Download of https://www.kaggle.com/datasets/jacquelineguzman/claims-of-medical-billing/\n",
    "file_cvs = \"claims.csv\"\n",
    "# Create dataframe with information of file CSV\n",
    "df = pd.read_csv(file_cvs, delimiter=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4fe970-1855-45b0-829b-58a2cc583d2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tratamiento de datos previos a la aplicación del modelo de clasificación\n",
    "##### Se define como variable objetivo la marca de si el registro tiene reclamación o no (CLAIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2056c09-98f1-4a75-8a7c-e69038f5ffad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define colums target (CLAIM)\n",
    "columns = df.columns\n",
    "target = \"CLAIM\"\n",
    "x_columns = columns.drop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519af7a3-0ae7-458d-9f8d-e2f823b77dcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Se actualizan las variables para manejar tipos de datos a 32 bits, dado que usa menos recurso de memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6fa48a3-eb0d-41f6-90d4-09c889b6da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update datatype int64 to int32 and float64 to float32, because it is necessary to use less RAM\n",
    "float_columns = ['QUANTITY_PRODUCT_SERVICE', 'SALES_PRICE', 'INVOICED_PRICE']\n",
    "int_columns = columns.drop(float_columns)\n",
    "df[float_columns]=df[float_columns].astype(np.float32)\n",
    "df[int_columns]=df[int_columns].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a052d9f-3cd9-4f85-8464-cf8c1e6cc763",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Para facilitar los calculos del algoritmo se normaliza la información de las variables de entrada para que manejen rangos numericos entre cero (0) y uno (1), esto se hace con la función MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731b9441-7066-42ee-a3ec-b5e8b15b2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data via MinMaxScaler function\n",
    "scaler = MinMaxScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(df,columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffe7e0-9c2f-4ea8-8e32-2c456f2f40d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Se verifica la distribucción de la variable objetivo (CLAIM), donde se observa que es desbalanceda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cb5d8f1-b8ab-4eb9-82b6-dcbb70213ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLAIM:\n",
      "[0. 1.]\n",
      "\n",
      "CLAIM\n",
      "0.0    6104323\n",
      "1.0        120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Distribution of the target variable (CLAIM)\n",
    "print(str(target)+':\\n'+str(df[target].unique())+'\\n')\n",
    "print(df[target].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac53a78b-0f19-44dc-ae39-ed2ea7fc0d09",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Se crean los dataframe de entrada (ValX) y salida (ValY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9539c3-6aed-4d8d-9a4a-bb0e08d4212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with int variables (ValX) and target variable (ValY)\n",
    "ValX = df.drop(columns=target)\n",
    "ValY = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b4f368-88f4-4dc8-a111-3e26464bdc09",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Se crean los dataframe de entrenamiento y validación, necesarios para el entrenamiento del modelo, se definió un 15% de los datos para los dataframe de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3162f050-de3e-4980-b3a2-b9b461c91e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5188776, 53), (915667, 53))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set training and validation data\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(ValX, ValY, test_size=0.15, random_state=1, shuffle=True)\n",
    "X_train.shape, X_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f480f9-0a07-4ef1-9686-0be13e63a8db",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Para no trabajar con datos de entrenamiento desbalanceados, se aplica la técnica de sobremuestreo (over-sampling) sobre los datos de entrenamiento (X_train y Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8794b065-cf1a-4d56-91bf-009ba98aad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class using SMOTE stategy (Over-sampling)\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba08e7dc-297b-4789-94ca-ea123ed9d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\jefe.sistemas\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to generate the data.\n",
    "X_train, Y_train = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b789544-20c3-40b1-b591-6caf8bcb1c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10377344, 53), (915667, 53))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a91cd8d6-cc67-4ce6-87ac-79dcdf5ad010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "from typing import Optional, Union, Tuple\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import  mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(asctime)-5s %(name)-10s %(levelname)-5s %(message)s', \n",
    "    level  = logging.INFO,\n",
    ")\n",
    "\n",
    "\n",
    "def check_early_stopping(\n",
    "    scores: Union[list, np.ndarray],\n",
    "    metric: str,\n",
    "    stopping_rounds: int=4,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    max_runtime_sec: int=None,\n",
    "    start_time: pd.Timestamp=None) -> bool:\n",
    "    \n",
    "    \"\"\"\n",
    "    Check if early stopping condition is met.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric which scores referes to. Used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    stopping_rounds: int, default 4\n",
    "        Number of consecutive rounds without improvement needed to stop\n",
    "        the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement.\n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "    \n",
    "    start_time: pd.Timestamp, default `None`\n",
    "        Time when training started. Used to determine if `max_runtime_sec` has been\n",
    "        reached.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    bool:\n",
    "        `True` if any condition needed for early stopping is met. `False` otherwise.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    Example of early stopping:\n",
    "        \n",
    "    Stop after 4 rounds without an improvement of 1% or higher: `stopping_rounds` = 4,\n",
    "    `stopping_tolerance` = 0.01, `max_runtime_sec` = None.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    allowed_metrics = ['accuracy', 'auc', 'f1', 'mse', 'mae', 'squared_error',\n",
    "                       'absolute_error']\n",
    "    \n",
    "    if metric not in allowed_metrics:\n",
    "        raise Exception(\n",
    "                f\"`metric` argument must be one of: {allowed_metrics}. \"\n",
    "                f\"Got {metric}\"\n",
    "        )\n",
    "    \n",
    "    if isinstance(scores, list):\n",
    "        scores = np.array(scores)\n",
    "        \n",
    "    if max_runtime_sec is not None:\n",
    "        \n",
    "        if start_time is None:\n",
    "            start_time = pd.Timestamp.now()\n",
    "            \n",
    "        runing_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "        \n",
    "        if runing_time > max_runtime_sec:\n",
    "            logging.debug(\n",
    "                f\"Reached maximum time for training ({max_runtime_sec} seconds). \"\n",
    "                f\"Early stopping activated.\"\n",
    "            )\n",
    "            return True\n",
    "        \n",
    "    if len(scores) < stopping_rounds:\n",
    "        return False\n",
    "    \n",
    "    if metric in ['accuracy', 'auc', 'f1']:\n",
    "        # The higher the metric, the better\n",
    "        diff_scores = scores[1:] - scores[:-1]\n",
    "        improvement = diff_scores / scores[:-1]\n",
    "        \n",
    "    if metric in ['mse', 'mae', 'squared_error', 'absolute_error']:\n",
    "        # The lower the metric, the better\n",
    "        \n",
    "        # scores = -1 * scores \n",
    "        # diff_scores = scores[:-1] - scores[1:]\n",
    "        # improvement = diff_scores / scores[1:]\n",
    "        diff_scores = scores[1:] - scores[:-1]\n",
    "        improvement = diff_scores / scores[:-1]\n",
    "        improvement = -1 * improvement\n",
    "        \n",
    "    improvement = np.hstack((np.nan, improvement))\n",
    "    logging.debug(f\"Improvement: {improvement}\")\n",
    "    \n",
    "    if (improvement[-stopping_rounds:] < stopping_tolerance).all():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "def fit_RandomForest_early_stopping(\n",
    "    model: Union[RandomForestClassifier, RandomForestRegressor],\n",
    "    X: Union[np.ndarray, pd.core.frame.DataFrame],\n",
    "    y: np.ndarray,\n",
    "    metric: str,\n",
    "    positive_class: int=1,\n",
    "    score_tree_interval: int=None,\n",
    "    stopping_rounds: int=4,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    max_runtime_sec: int=None) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    Fit a RandomForest model until an early stopping condition is met or\n",
    "    `n_estimatos` is reached.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model: RandomForestClassifier, RandomForestRegressor\n",
    "        Model to be fitted.\n",
    "        \n",
    "    X: np.ndarray, pd.core.frame.DataFrame\n",
    "        Training input samples. \n",
    "    \n",
    "    y: np.ndarray, pd.core.frame.DataFrame\n",
    "        Target value of the input samples. \n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric used to generate the score. Used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    score_tree_interval: int, default `None`\n",
    "        Score the model after this many trees. If `None`, the model is scored after\n",
    "        `n_estimators` / 10.\n",
    "        \n",
    "    stopping_rounds: int\n",
    "        Number of consecutive rounds without improvement needed to stop the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement. \n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    oob_scores: np.ndarray\n",
    "        Out of bag score for each scoring point.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if score_tree_interval is None:\n",
    "        score_tree_interval = int(model.n_estimators / 10)\n",
    "        \n",
    "    allowed_metrics = ['accuracy', 'auc', 'f1', 'mse', 'mae', 'squared_error',\n",
    "                       'absolute_error']\n",
    "    \n",
    "    if metric not in allowed_metrics:\n",
    "        raise Exception(\n",
    "                f\"`metric` argument must be one of: {allowed_metrics}. \"\n",
    "                f\"Got {metric}\"\n",
    "        )\n",
    "    \n",
    "    if not model.oob_score:\n",
    "        model.set_params(oob_score=True)\n",
    "        \n",
    "    start_time = pd.Timestamp.now()\n",
    "    oob_scores = []\n",
    "    scoring_points = np.arange(0, model.n_estimators + 1, score_tree_interval)[1:]\n",
    "    scoring_points = np.hstack((1, scoring_points))\n",
    "    \n",
    "    metrics = {\n",
    "        'auc' : roc_auc_score,\n",
    "        'accuracy' : accuracy_score,\n",
    "        'f1': f1_score,\n",
    "        'mse': mean_squared_error,\n",
    "        'squared_error': mean_squared_error,\n",
    "        'mae': mean_absolute_error,\n",
    "        'absolute_error': mean_absolute_error,        \n",
    "    }\n",
    "    \n",
    "    for i, n_estimators in enumerate(scoring_points):\n",
    "        \n",
    "        logging.debug(f\"Training with n_stimators: {n_estimators}\")\n",
    "        model.set_params(n_estimators=n_estimators)\n",
    "        model.fit(X=X, y=y)\n",
    "        \n",
    "        if metric == 'auc':\n",
    "            oob_predictions = model.oob_decision_function_[:, positive_class]\n",
    "            # If n_estimators is small it might be possible that a data point\n",
    "            # was never left out during the bootstrap. In this case,\n",
    "            # oob_decision_function_ might contain NaN.\n",
    "            oob_score = metrics[metric](\n",
    "                            y_true=y[~np.isnan(oob_predictions)],\n",
    "                            y_score=oob_predictions[~np.isnan(oob_predictions)]\n",
    "                        )\n",
    "        else:\n",
    "            oob_predictions = model.oob_decision_function_\n",
    "            oob_predictions = np.argmax(oob_predictions, axis=1)\n",
    "            oob_score = metrics[metric](\n",
    "                            y_true=y[~np.isnan(oob_predictions)],\n",
    "                            y_score=oob_predictions[~np.isnan(oob_predictions)]\n",
    "                        )\n",
    "            \n",
    "        oob_scores.append(oob_score)\n",
    "        \n",
    "        early_stopping = check_early_stopping(\n",
    "                            scores             = oob_scores,\n",
    "                            metric             = metric,\n",
    "                            stopping_rounds    = stopping_rounds,\n",
    "                            stopping_tolerance = stopping_tolerance,\n",
    "                            max_runtime_sec    = max_runtime_sec,\n",
    "                            start_time         = start_time\n",
    "                         )    \n",
    "        \n",
    "        if early_stopping:\n",
    "            logging.debug(\n",
    "                f\"Early stopping activated at round {i + 1}: n_estimators = {n_estimators}\"\n",
    "            )\n",
    "            break\n",
    "        \n",
    "    logging.debug(f\"Out of bag score = {oob_scores[-1]}\")\n",
    "    \n",
    "    return np.array(oob_scores), scoring_points[:len(oob_scores)]\n",
    "    \n",
    "\n",
    "def custom_gridsearch_RandomForestClassifier(\n",
    "    model: RandomForestClassifier,\n",
    "    X: Union[np.ndarray, pd.core.frame.DataFrame],\n",
    "    y: np.ndarray,\n",
    "    metric: str,\n",
    "    param_grid: dict,\n",
    "    positive_class: int=1,\n",
    "    score_tree_interval: int=None,\n",
    "    stopping_rounds: int=5,\n",
    "    stopping_tolerance: float=0.01,\n",
    "    model_max_runtime_sec: int=None,\n",
    "    max_models: int=None,\n",
    "    max_runtime_sec: int=None,\n",
    "    return_best: bool=True) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    '''\n",
    "    Grid search for RandomForestClassifier model based on out-of-bag metric and \n",
    "    early stopping for each model fit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    model: RandomForestClassifier\n",
    "        Model to search over.\n",
    "           \n",
    "    X: np.ndarray, pd.core.frame.DataFrame\n",
    "        The training input samples. \n",
    "    \n",
    "    y: np.ndarray, pd.core.frame.DataFrame\n",
    "        The target of input samples. \n",
    "    \n",
    "    scores: list, np.ndarray\n",
    "        Scores used to evaluate early stopping conditions.\n",
    "        \n",
    "    metric: str\n",
    "        Metric used to generate the score. I is used to determine if higher score\n",
    "        means a better model or the opposite.\n",
    "        \n",
    "    score_tree_interval: int, default `None`\n",
    "        Score the model after this many trees. If `None`, the model is scored after\n",
    "        `n_estimators` / 10.\n",
    "        \n",
    "    stopping_rounds: int\n",
    "        Number of consecutive rounds without improvement needed to stop the training.\n",
    "    \n",
    "    stopping_tolerance: float, default 0.01\n",
    "        Minimum percentage of positive change between two consecutive rounds\n",
    "        needed to consider it as an improvement. \n",
    "    \n",
    "    model_max_runtime_sec: int, default `None`\n",
    "        Maximum allowed runtime in seconds for model training. `None` means unlimited.\n",
    "        \n",
    "    max_models: int, default `None`\n",
    "        Maximum number of models trained during the search.\n",
    "    \n",
    "    max_runtime_sec: int, default `None`\n",
    "        Maximum number of seconds for the search.\n",
    "        \n",
    "    return_best : bool\n",
    "        Refit model using the best found parameters on the whole data.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    \n",
    "    results: pd.DataFrame\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    results = {'params': [], 'oob_metric': []}\n",
    "    start_time = pd.Timestamp.now()\n",
    "    history_scores = {}\n",
    "    history_scoring_points = np.array([], dtype = int)\n",
    "    param_grid = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    if not model.oob_score:\n",
    "        model.set_params(oob_score=True)\n",
    "    \n",
    "    if max_models is not None and max_models < len(param_grid):\n",
    "        param_grid = np.random.choice(param_grid, max_models)\n",
    "\n",
    "    for params in tqdm.tqdm(param_grid):\n",
    "        \n",
    "        if max_runtime_sec is not None:\n",
    "            runing_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "            if runing_time > max_runtime_sec:\n",
    "                logging.info(\n",
    "                    f\"Reached maximum time for GridSearch ({max_runtime_sec} seconds). \"\n",
    "                    f\"Search stopped.\"\n",
    "                )\n",
    "                break   \n",
    "        \n",
    "        model.set_params(**params)\n",
    "\n",
    "        oob_scores, scoring_points = fit_RandomForest_early_stopping(\n",
    "                                        model = clone(model), # Clone to avoid modification of n_estimators\n",
    "                                        X = X,\n",
    "                                        y = y,\n",
    "                                        metric = metric,\n",
    "                                        positive_class      = positive_class,\n",
    "                                        score_tree_interval = score_tree_interval,\n",
    "                                        stopping_rounds     = stopping_rounds,\n",
    "                                        stopping_tolerance  = stopping_tolerance,\n",
    "                                        max_runtime_sec     = model_max_runtime_sec\n",
    "                                     )\n",
    "      \n",
    "        history_scoring_points = np.union1d(history_scoring_points,  scoring_points)        \n",
    "        history_scores[str(params)] = oob_scores\n",
    "        params['n_estimators'] = scoring_points[-1]\n",
    "        results['params'].append(params)\n",
    "        results['oob_metric'].append(oob_scores[-1])\n",
    "        logging.debug(f\"Modelo: {params} \\u2713\")\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    history_scores = pd.DataFrame(\n",
    "                            dict([(k, pd.Series(v)) for k,v in history_scores.items()])\n",
    "                         )\n",
    "    history_scores['n_estimators'] = history_scoring_points\n",
    "    \n",
    "    if metric in ['accuracy', 'auc', 'f1']:\n",
    "        results = results.sort_values('oob_metric', ascending=False)\n",
    "    else:\n",
    "        results = results.sort_values('oob_metric', ascending=True)\n",
    "        \n",
    "    results = results.rename(columns = {'oob_metric': f'oob_{metric}'})\n",
    "    \n",
    "    if return_best:\n",
    "        best_params = results['params'].iloc[0]\n",
    "        print(\n",
    "            f\"Refitting mode using the best found parameters and the whole data set: \\n {best_params}\"\n",
    "        )\n",
    "        \n",
    "        model.set_params(**best_params)\n",
    "        model.fit(X=X, y=y)\n",
    "        \n",
    "    results = pd.concat([results, results['params'].apply(pd.Series)], axis=1)\n",
    "    results = results.drop(columns = 'params')\n",
    "    \n",
    "    return results, history_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9375f009-e7bf-45a1-af8e-5f8854427423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Búsqueda de mejor modelo basada en métrica out-of-bag\u001b[39;00m\n\u001b[0;32m     17\u001b[0m start \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m---> 19\u001b[0m resultados, history \u001b[38;5;241m=\u001b[39m custom_gridsearch_RandomForestClassifier(\n\u001b[0;32m     20\u001b[0m                         model                 \u001b[38;5;241m=\u001b[39m model,\n\u001b[0;32m     21\u001b[0m                         X                     \u001b[38;5;241m=\u001b[39m X_train,\n\u001b[0;32m     22\u001b[0m                         y                     \u001b[38;5;241m=\u001b[39m X_train,\n\u001b[0;32m     23\u001b[0m                         metric                \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m                         param_grid            \u001b[38;5;241m=\u001b[39m param_grid,\n\u001b[0;32m     25\u001b[0m                         positive_class        \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     26\u001b[0m                         score_tree_interval   \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     27\u001b[0m                         stopping_rounds       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     28\u001b[0m                         stopping_tolerance    \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m,\n\u001b[0;32m     29\u001b[0m                         model_max_runtime_sec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m                         max_models            \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     31\u001b[0m                         max_runtime_sec       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m                         return_best           \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     33\u001b[0m                       )\n\u001b[0;32m     35\u001b[0m end \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuración búsqueda: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;241m-\u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 353\u001b[0m, in \u001b[0;36mcustom_gridsearch_RandomForestClassifier\u001b[1;34m(model, X, y, metric, param_grid, positive_class, score_tree_interval, stopping_rounds, stopping_tolerance, model_max_runtime_sec, max_models, max_runtime_sec, return_best)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m   \n\u001b[0;32m    351\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 353\u001b[0m oob_scores, scoring_points \u001b[38;5;241m=\u001b[39m fit_RandomForest_early_stopping(\n\u001b[0;32m    354\u001b[0m                                 model \u001b[38;5;241m=\u001b[39m clone(model), \u001b[38;5;66;03m# Clone to avoid modification of n_estimators\u001b[39;00m\n\u001b[0;32m    355\u001b[0m                                 X \u001b[38;5;241m=\u001b[39m X,\n\u001b[0;32m    356\u001b[0m                                 y \u001b[38;5;241m=\u001b[39m y,\n\u001b[0;32m    357\u001b[0m                                 metric \u001b[38;5;241m=\u001b[39m metric,\n\u001b[0;32m    358\u001b[0m                                 positive_class      \u001b[38;5;241m=\u001b[39m positive_class,\n\u001b[0;32m    359\u001b[0m                                 score_tree_interval \u001b[38;5;241m=\u001b[39m score_tree_interval,\n\u001b[0;32m    360\u001b[0m                                 stopping_rounds     \u001b[38;5;241m=\u001b[39m stopping_rounds,\n\u001b[0;32m    361\u001b[0m                                 stopping_tolerance  \u001b[38;5;241m=\u001b[39m stopping_tolerance,\n\u001b[0;32m    362\u001b[0m                                 max_runtime_sec     \u001b[38;5;241m=\u001b[39m model_max_runtime_sec\n\u001b[0;32m    363\u001b[0m                              )\n\u001b[0;32m    365\u001b[0m history_scoring_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munion1d(history_scoring_points,  scoring_points)        \n\u001b[0;32m    366\u001b[0m history_scores[\u001b[38;5;28mstr\u001b[39m(params)] \u001b[38;5;241m=\u001b[39m oob_scores\n",
      "Cell \u001b[1;32mIn[15], line 218\u001b[0m, in \u001b[0;36mfit_RandomForest_early_stopping\u001b[1;34m(model, X, y, metric, positive_class, score_tree_interval, stopping_rounds, stopping_tolerance, max_runtime_sec)\u001b[0m\n\u001b[0;32m    216\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with n_stimators: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_estimators\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    217\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(n_estimators\u001b[38;5;241m=\u001b[39mn_estimators)\n\u001b[1;32m--> 218\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    221\u001b[0m     oob_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39moob_decision_function_[:, positive_class]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:421\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of y is not strictly positive which \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis necessary for Poisson regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m         )\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m--> 421\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y_class_weight(y)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m    424\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(y, dtype\u001b[38;5;241m=\u001b[39mDOUBLE)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:831\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m--> 831\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    833\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    834\u001b[0m     expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m ]:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "# Grid de valores sobre los que buscar\n",
    "param_grid = {\n",
    "             'max_depth'   : [3, 10, 20],\n",
    "             'min_samples_leaf': [0.05, 0.1],\n",
    "             'max_features': ['sqrt', 'log2'],\n",
    "             'ccp_alpha': [0, 0.01]\n",
    "            }\n",
    "# Modelo\n",
    "model = RandomForestClassifier(\n",
    "            n_estimators = 1000,\n",
    "            oob_score    = True,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 123\n",
    "        )\n",
    "\n",
    "# Búsqueda de mejor modelo basada en métrica out-of-bag\n",
    "start = pd.Timestamp.now()\n",
    "\n",
    "resultados, history = custom_gridsearch_RandomForestClassifier(\n",
    "                        model                 = model,\n",
    "                        X                     = X_train,\n",
    "                        y                     = X_train,\n",
    "                        metric                = 'auc',\n",
    "                        param_grid            = param_grid,\n",
    "                        positive_class        = 1,\n",
    "                        score_tree_interval   = 50,\n",
    "                        stopping_rounds       = 4,\n",
    "                        stopping_tolerance    = 0.01,\n",
    "                        model_max_runtime_sec = None,\n",
    "                        max_models            = None,\n",
    "                        max_runtime_sec       = None,\n",
    "                        return_best           = True\n",
    "                      )\n",
    "\n",
    "end = pd.Timestamp.now()\n",
    "print(f\"Duración búsqueda: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c13197-8944-4d7c-82b5-c81370d1aeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
